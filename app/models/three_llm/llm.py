########################### SETP 2 : LLM #####################################

import openai
import os
import requests
import json
import numpy as np
from dotenv import load_dotenv
from groq import Groq
from langchain.prompts import PromptTemplate
import numpy as np
import torch
from PIL import Image

from transformers import BlipProcessor, BlipForConditionalGeneration
from one_imageDetection.opencv_utils import get_color_name

# DeepSeek API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •
client = Groq(api_key="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")


# # OpenAI API í‚¤ ì„¤ì • (ìì‹ ì˜ API í‚¤ ì…ë ¥)
# openai.api_key = "YOUR_API_KEY"

def generate_blip_description(image_path):
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large").to("cuda" if torch.cuda.is_available() else "cpu")

    image = Image.open(image_path).convert("RGB")
    inputs = processor(images=image, return_tensors="pt").to("cuda" if torch.cuda.is_available() else "cpu")

    prompt = "Describe this painting's scene, colors, composition, and mood in detail."
    
    # ğŸ”¹ í”„ë¡¬í”„íŠ¸ë¥¼ input_idsë¡œ ë³€í™˜
    prompt_inputs = processor.tokenizer(prompt, return_tensors="pt").to("cuda" if torch.cuda.is_available() else "cpu")
    
    with torch.no_grad():
        output_with_prompt = model.generate(**inputs, input_ids=prompt_inputs.input_ids, max_length=150)
        caption_with_prompt = processor.batch_decode(output_with_prompt, skip_special_tokens=True)[0]

    print(f"ğŸ”¹ **BLIP Prompt-Based Caption:** {caption_with_prompt}")

    return caption_with_prompt

def generate_rich_description(title, blip_desc, dominant_colors, edges):
    color_names = [get_color_name(c) for c in dominant_colors[:5]]
    dominant_colors_text = ", ".join(color_names)
    edges_detected = "ëª…í™•íˆ íƒì§€ë¨" if np.sum(edges) > 10000 else "ë¶ˆëª…í™•í•˜ê²Œ íƒì§€ë¨"

    prompt_template = PromptTemplate(
        input_variables=["title", "blip_desc", "dominant_colors", "edges_detected"],
        template=f"""
        Please generate a detailed description of the painting titled **"{title}"**.  

        - **Painting description (BLIP):** {blip_desc}  
        - **Dominant Colors (Natural Language):** {dominant_colors_text}  
        - **Edge Detection Analysis:** {edges_detected}  

        The text **must consist ONLY of Korean Hangul syllables (ê°€-í£), without any exceptions**.  
        """
    )

    formatted_prompt = prompt_template.format(
        title=title,
        blip_desc=blip_desc,
        dominant_colors=dominant_colors_text,
        edges_detected=edges_detected
    )
    
    completion = client.chat.completions.create(
        model="qwen-2.5-coder-32b",
        messages=[{"role": "user", "content": formatted_prompt}],
        temperature=0.5,
        max_tokens=1024,
        top_p=0.95
    )
    
    return completion.choices[0].message.content.strip()


########################### SETP 3 : TTS #####################################
from gtts import gTTS
import os

def text_to_speech(text, output_file="output.mp3"):
    """
    ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜.

    Parameters:
        text (str): ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
        output_file (str): ì €ì¥í•  ìŒì„± íŒŒì¼ì˜ ì´ë¦„ (ê¸°ë³¸ê°’: "output.mp3")
    """
    try:
        if "<think>" in text:
            text = text.split("</think>")[-1].strip()

        # gTTSë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        tts = gTTS(text=text, lang='ko')  # í•œêµ­ì–´ ì‚¬ìš© ì‹œ lang='ko'ë¡œ ë³€ê²½
        tts.save(output_file)
        print(f"ìŒì„± íŒŒì¼ì´ '{output_file}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì €ì¥ëœ ìŒì„± íŒŒì¼ ì‹¤í–‰
        os.system(f"start {output_file}")  # Windows ì‚¬ìš© (macOSëŠ” open, LinuxëŠ” xdg-open)
    except Exception as e:
        print(f"ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")